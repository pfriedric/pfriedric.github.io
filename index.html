<!DOCTYPE HTML>
<html lang="en">
  <head>
  	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Paul Friedrich</title>
  
    <meta name="author" content="Paul Friedrich">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
</head>

<script type="text/javascript">
function toggle_vis(id) {
    var e = document.getElementById(id);
    if (e.style.display == 'none')
    e.style.display = 'inline';
    else
    e.style.display = 'none';
}
</script>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <h1>
                	Paul Friedrich
                </h1>
              </p>
              <p> I am a Computer Science PhD student in the <a href="https://www.ifi.uzh.ch/en.html">Department of Informatics</a> at the <a href="https://www.uzh.ch/en.html">University of Zurich</a>, co-advised by <a href="https://www.ifi.uzh.ch/en/ce/people/seuken.html">Sven Seuken</a> and <a href="https://gioramponi.github.io/">Giorgia Ramponi</a>. I am associated with the <a href="https://ai.ethz.ch/">ETH AI Center</a>. In my research, I am interested in using machine and reinforcement learning to analyze and shape equilibria in games and marketplaces, and design more fair and efficient mechanisms.
              </p>
              <p> I hold a Master's (since 2020) and Bachelor's (since 2018) degree in Mathematics from <a href="https://ethz.ch/de.html">ETH Zurich</a>, advised by <a href="https://people.math.ethz.ch/~jteichma/">Josef Teichmann</a>. There, I focused on probability theory, mathematical finance, and machine learning. In 2017, I spent a semester abroad at the Hong Kong University of Science and Technology.
              </p>
              <p> During and after my studies, I worked as a consultant in the risk management practice of <a href="https://www.ey.com/en_ch">Ernst & Young Switzerland</a>. Outside of work you can catch me running, or enjoying pretty much any sport on, in and below the water.
              </p>
              <p>
              	If you are offering a research internship for which I could fit well or are interested in collaborating, please reach out!
              </p>
              <p style="text-align:center">
                <a href="mailto:paul.friedrich@uzh.ch">Email</a> &nbsp/&nbsp
                <a href="data/cv_paul_friedrich.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=B-QCNA0AAAAJ">Google Scholar</a> &nbsp/&nbsp
<!--                <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp-->
                <a href="https://github.com/pfriedric/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/paul-friedrich-924005162">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/paul.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/paul.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


            <!-- </p> -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tbody><tr><td>
                <heading>News</heading>
                <ul>
                    <li>I am happy to be part of the ELLIS community.</li>
                    <li>Our paper <a href="https://arxiv.org/pdf/2306.14799.pdf">On Imitation in Mean-field Games"</a> has been accepted at NeurIPS 2023! </li>
                    <li>I was invited as lecturer at the Mediterranean Machine Learning Summer School to talk about Deep Reinforcement Learning.</li>
                    <li>I gave a talk on Reinforcement Learning and Multi-agent Learning at the New Frontiers in Learning, Control, and Dynamical Systems workshop at ICML 2023. See everyone in Hawaii!</li>
                    <li>Four papers accepted at EWRL 2023!</li>
                    <li> Designing and teaching a new course called Data Science and Machine Learning for the ETH-Ashesi Master program.</li>
                    <li>Two papers accepted at NeurIPS 2022! <a href="https://arxiv.org/abs/2207.08645">"Active Exploration for Inverse Reinforcement Learning"</a> and <a href="https://arxiv.org/abs/2210.11137">"Trust Region Policy Optimization with Optimal Transport Discrepancies: Duality and Algorithm for Continuous Actions"</a>.</li>
                    <li>Our open problem "Do you pay for Privacy in Online learning?" has been selected at COLT 2022.</li>
                    <li>Our paper "Active Exploration for Inverse Reinforcement Learning" has been accepted at the Adaptive Experimental Design and Active Learning in the Real World (ReALML) workshop at ICML 2022.</li>
                    <li>Our paper <a href="https://openreview.net/pdf?id=S3NzSD8icx9">"Learning in Markov Games: can we exploit a general-sum opponent?" </a> has been accepted as oral (~4%) at UAI 2022.</li>
                     <a href="javascript:toggle_vis('news')">show more</a>
                    <div id="news" style="display:none">
                    <li> Designing and teaching a new course at ETH Zürich with AI Center postdocs in the spring term. The course is on various advanced topics including Inverse Reinforcement Learning.</li>
                    <li>I will visit the <a href="https://simons.berkeley.edu/">Simons Institute</a> in January-February 2022 for the Learning and Games program.</li>
                    <li>Our paper "Learning in Non-Cooperative Configurable Markov Decision Process" has been accepted at NeurIPS 2021.</li>
                    <li>18.08.2021 I was selected to participate in the <a href="https://risingstars21-eecs.mit.edu/">EECS RISING STARS 2021</a>.
                    <li>In August 2021 I joined the ETH AI Center as postdoctoral researcher.</li>
                    <li>In June 2021 I completed my Ph.D.!</li>
                    <li>Our paper "Provably Efficient Learning of Transferable Rewards" has been accepted at ICML 2021.</li>
                    <li>Our paper "Dealing with multiple experts and non-stationarity in inverse reinforcement learning: an application to real-life problems" has been published in the Machine Learning journal.</li>
                    <li>Our paper ‘‘Online Learning in Non-Cooperative Configurable Markov Decision Process’’ has been accepted at RLG 2021 workshop at AAAI.</li>
                    <li>Our paper ‘‘Newton Optimization on Helmholtz Decomposition for Continuous Games’’ has been accepted at AAAI2021.</li>
                    <li>Our paper ‘‘Handling Non-Stationary Experts in Inverse Reinforcement Learning: A Water System Control Case Study’’ has been accepted at Challenges of Real World Reinforcement Learning Workshop, and ‘‘Newton-based Policy Optimization for Games’’ has been accepted at CooperativeAI workshop.</li>
                    <li>Our paper ‘‘Controlled Text Generation with Adversarial Learning’’ has been accepted at INLG 2020.</li>
                    <li>Our paper "Inverse Reinforcement Learning from a Gradient-based Learner" has been accepted at NeurIPS 2020. </li>
                    <li>Our paper ‘‘Truly Batch Model-Free Inverse Reinforcement Learning about Multiple Intentions’’ has been accepted at AISTATS 2020.</li>
                    </div>
                </ul>
            </td></tr>


            </tbody></table>
    


        </tbody></table> -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design from <a style="fonr-size:small" href="https://jonbarron.info">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
